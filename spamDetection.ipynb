{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import nltk\n",
        "import csv"
      ],
      "metadata": {
        "id": "mtFKEGH58LHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8Yt7jkO8Psv",
        "outputId": "cd7dcf1f-1d4c-4dea-8f3a-0782fded7ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/spamdetection/spam.csv'\n",
        "raw_df = pd.read_csv(file_path, encoding='ISO-8859-1', header=None)\n",
        "print(raw_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKa2Z-W_8Uyz",
        "outputId": "caba095e-7483-4236-a23a-985423b33037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0                                                  1    2    3    4\n",
            "0    v1                                                 v2  NaN  NaN  NaN\n",
            "1   ham  Go until jurong point, crazy.. Available only ...  NaN  NaN  NaN\n",
            "2   ham                      Ok lar... Joking wif u oni...  NaN  NaN  NaN\n",
            "3  spam  Free entry in 2 a wkly comp to win FA Cup fina...  NaN  NaN  NaN\n",
            "4   ham  U dun say so early hor... U c already then say...  NaN  NaN  NaN\n",
            "5   ham  Nah I don't think he goes to usf, he lives aro...  NaN  NaN  NaN\n",
            "6  spam  FreeMsg Hey there darling it's been 3 week's n...  NaN  NaN  NaN\n",
            "7   ham  Even my brother is not like to speak with me. ...  NaN  NaN  NaN\n",
            "8   ham  As per your request 'Melle Melle (Oru Minnamin...  NaN  NaN  NaN\n",
            "9  spam  WINNER!! As a valued network customer you have...  NaN  NaN  NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all columns into a single string per row\n",
        "raw_df['text'] = raw_df.iloc[:, 1:].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
        "raw_df = raw_df[[0, 'text']]\n",
        "raw_df.columns = ['label', 'text']"
      ],
      "metadata": {
        "id": "Xv2FhxPt8Xg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzriANRs8dDc",
        "outputId": "d3179d8a-65fb-41b5-d765-e35f2aff6768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                               text\n",
            "0    v1                                                 v2\n",
            "1   ham  Go until jurong point, crazy.. Available only ...\n",
            "2   ham                      Ok lar... Joking wif u oni...\n",
            "3  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "4   ham  U dun say so early hor... U c already then say...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the data distribution\n",
        "print(raw_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-bZw3td8giN",
        "outputId": "4534e4f2-8508-4abd-dd78-6f1e9c9f5965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "ham     4825\n",
            "spam     747\n",
            "v1         1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, float):  # Handle non-string inputs\n",
        "        return ''\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    words = text.split()  # Tokenize\n",
        "    stop_words = set(stopwords.words('english'))  # Remove stopwords\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    stemmer = SnowballStemmer('english')  # Stemming\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "dCzTejvi8o7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle NaN values in the 'text' column\n",
        "raw_df['text'] = raw_df['text'].fillna('')\n",
        "\n",
        "# Ensure all values are strings\n",
        "raw_df['text'] = raw_df['text'].astype(str)\n",
        "\n",
        "# Apply preprocessing to the text data\n",
        "raw_df['processed_text'] = raw_df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "I46IxKUB8wCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for empty strings after preprocessing\n",
        "print(f\"Number of samples in processed text: {len(raw_df['processed_text'])}\")\n",
        "print(f\"Number of empty strings in processed text: {sum(raw_df['processed_text'] == '')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CYAGr748xBs",
        "outputId": "c26afd07-27a7-425f-d9b8-3221f3bbd3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in processed text: 5573\n",
            "Number of empty strings in processed text: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove empty strings if any\n",
        "raw_df = raw_df[raw_df['processed_text'] != '']"
      ],
      "metadata": {
        "id": "TZVXE-hP81kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure there are still samples left after filtering\n",
        "print(f\"Number of samples after removing empty strings: {len(raw_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHtqSeaI881d",
        "outputId": "b849ba25-77ac-4621-9a24-f7386370ba56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples after removing empty strings: 5568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(raw_df['processed_text'], raw_df['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "vBYc_sna9AyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "qq-v1n0b9E-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "VXqWW9DP9JIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the testing data\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "dzk9pP1-9OWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "nb_model = MultinomialNB()\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "svm_model = SVC(kernel='linear')"
      ],
      "metadata": {
        "id": "6_Toinm79S3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "svm_model.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "_tdRRjHR9cxi",
        "outputId": "d6e4b18c-02a2-4dd7-8b0e-929d39adc70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "nb_pred = nb_model.predict(X_test_tfidf)\n",
        "lr_pred = lr_model.predict(X_test_tfidf)\n",
        "svm_pred = svm_model.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "KTEwGwFQ9duQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out unexpected values from y_test\n",
        "valid_labels = ['ham', 'spam']\n",
        "y_test_filtered = y_test[y_test.isin(valid_labels)]"
      ],
      "metadata": {
        "id": "7i5gJ29K9h04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter predictions accordingly\n",
        "nb_pred_filtered = nb_pred[y_test.isin(valid_labels)]\n",
        "lr_pred_filtered = lr_pred[y_test.isin(valid_labels)]\n",
        "svm_pred_filtered = svm_pred[y_test.isin(valid_labels)]"
      ],
      "metadata": {
        "id": "9h6N6OmW9m0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models\n",
        "def evaluate_model(y_test, y_pred):\n",
        "    # Calculate confusion matrix\n",
        "    try:\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=valid_labels).ravel()\n",
        "    except ValueError:\n",
        "        tn = fp = fn = tp = 0\n",
        "\n",
        "    # Calculate precision, recall, and F1-score\n",
        "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) != 0 else 0\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "yvHgOEXv9slG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model\n",
        "nb_results = evaluate_model(y_test_filtered, nb_pred_filtered)\n",
        "lr_results = evaluate_model(y_test_filtered, lr_pred_filtered)\n",
        "svm_results = evaluate_model(y_test_filtered, svm_pred_filtered)"
      ],
      "metadata": {
        "id": "RblS_1AL900U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure results are not None or NaN\n",
        "nb_results = [0 if pd.isna(x) else x for x in nb_results]\n",
        "lr_results = [0 if pd.isna(x) else x for x in lr_results]\n",
        "svm_results = [0 if pd.isna(x) else x for x in svm_results]"
      ],
      "metadata": {
        "id": "XWuv2xFg96SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "print(\"Naive Bayes Results: Accuracy = {:.2f}, Precision = {:.2f}, Recall = {:.2f}, F1-Score = {:.2f}\".format(*nb_results))\n",
        "print(\"Logistic Regression Results: Accuracy = {:.2f}, Precision = {:.2f}, Recall = {:.2f}, F1-Score = {:.2f}\".format(*lr_results))\n",
        "print(\"SVM Results: Accuracy = {:.2f}, Precision = {:.2f}, Recall = {:.2f}, F1-Score = {:.2f}\".format(*svm_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcAqhQ64-FlV",
        "outputId": "a7621509-3ebb-4f44-d724-595b3428beb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Results: Accuracy = 0.96, Precision = 1.00, Recall = 0.72, F1-Score = 0.84\n",
            "Logistic Regression Results: Accuracy = 0.97, Precision = 0.99, Recall = 0.84, F1-Score = 0.91\n",
            "SVM Results: Accuracy = 0.98, Precision = 0.99, Recall = 0.90, F1-Score = 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare models\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Naive Bayes', 'Logistic Regression', 'SVM'],\n",
        "    'Accuracy': [nb_results[0], lr_results[0], svm_results[0]],\n",
        "    'Precision': [nb_results[1], lr_results[1], svm_results[1]],\n",
        "    'Recall': [nb_results[2], lr_results[2], svm_results[2]],\n",
        "    'F1-Score': [nb_results[3], lr_results[3], svm_results[3]]\n",
        "})\n",
        "\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9FNsI-l9_Yd",
        "outputId": "77ae328f-0b7d-47b7-98c6-a945705b6239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model  Accuracy  Precision    Recall  F1-Score\n",
            "0          Naive Bayes  0.958707   1.000000  0.722892  0.839161\n",
            "1  Logistic Regression  0.974865   0.992857  0.837349  0.908497\n",
            "2                  SVM  0.983842   0.986842  0.903614  0.943396\n"
          ]
        }
      ]
    }
  ]
}